{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05a4a9c",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfaa92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80c49b",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d614a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('features.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Split into feature and target\n",
    "X = df.drop(['timestamp', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Discretize target into binary classes\n",
    "y_binary = np.where(y > 0, 1, 0)  \n",
    "\n",
    "# Train test split\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y_binary[:split_idx], y_binary[split_idx:]\n",
    "\n",
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed5f553",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54660be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = xgb.XGBClassifier(random_state=11)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [3, 9],\n",
    "    'learning_rate': [0.05, 0.2],\n",
    "    'subsample': [0.7, 1.0],\n",
    "    'colsample_bytree': [0.7, 1.0],\n",
    "    'reg_alpha': [0, 0.2],\n",
    "    'reg_lambda': [0, 0.2]\n",
    "}\n",
    "\n",
    "ts_split = TimeSeriesSplit(n_splits=3)\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, cv=ts_split, \n",
    "                           scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, 'xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db74f3e",
   "metadata": {},
   "source": [
    "#### Model results\n",
    "The model performance looks unexceptional, this may be due to lack of training data (only ~1600), or could reflect low information that can be extracted from our features\n",
    "\n",
    "either 1. continue to train the model using new data after deployment, or 2. try to extract more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dc6dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Split 0: 0.5354\n",
      "Split 1: 0.5666\n",
      "Split 2: 0.5609\n",
      "Test: 0.5311\n"
     ]
    }
   ],
   "source": [
    "# Model performance on cross validation splits\n",
    "results = []\n",
    "for i, (train_idx, eval_idx) in enumerate(ts_split.split(X_train)):\n",
    "    model = clone(best_model)\n",
    "    model.fit(X_train.iloc[train_idx], y_train[train_idx])\n",
    "    y_pred = model.predict(X_train.iloc[eval_idx])\n",
    "    acc = accuracy_score(y_train[eval_idx], y_pred)\n",
    "    results.append(f\"Split {i}: {acc:.4f}\")\n",
    "\n",
    "# Model performance on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "results.append(f\"Test: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nResults:\\n\" + \"\\n\".join(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
